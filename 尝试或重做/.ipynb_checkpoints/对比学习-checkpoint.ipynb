{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae61f855-44e7-4409-b34f-3c28b378edb1",
   "metadata": {},
   "source": [
    "本次对比学习实验以pytorch作为基础框架。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6636e03-0e0e-4291-a321-7c6ac3d19db8",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bf24ce03-c0e4-45c4-8740-660377fe6f7d",
   "metadata": {},
   "source": [
    "定义多个用于存储信息的超参数\n",
    "    device：模型运行所在设备\n",
    "    batch_size：批样本大小\n",
    "    loss_list: 损失函数列表\n",
    "    transform: 数据加载过程中对数据进行处理的方法\n",
    "通过torch中包含的数据集加载方式加载MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4019152c-9c38-4789-ab9d-35cd3c59acf5",
   "metadata": {},
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 256\n",
    "loss_list = []\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "train_data = datasets.MNIST(root='../data', train=True, transform=transform, download=True)\n",
    "test_data = datasets.MNIST(root='../data', train=False, transform=transform, download=True)\n",
    "epochs = 40\n",
    "learning_rate = 7e-4"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f0c91716-da76-471f-aba8-50991b33f607",
   "metadata": {},
   "source": [
    "定义函数以获取数据集中对应的数据用于构建自定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "087ee017-3344-4445-9c74-a202d683f804",
   "metadata": {},
   "source": [
    "def get_data(dataset):\n",
    "    x_data, y_data = [], []\n",
    "    for i in range(len(dataset)):\n",
    "        x, y = dataset[i]\n",
    "        x_data.append(x)\n",
    "        y_data.append(y)\n",
    "    return x_data, y_data"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9c757c88-c2e6-4cb5-9754-44d59aaa958a",
   "metadata": {},
   "source": [
    "定义了一个自定义的数据集类 my_dataset，继承自 PyTorch 的 Dataset 类，主要用于从给定的输入数据和标签数据中创建一个数据集对象。\n",
    "    获取数据样本\n",
    "        根据给定的索引，从输入数据和标签数据中提取相应的样本 x 和标签 y。\n",
    "        随机生成两个索引 idx1 和 idx2，分别用于选择与当前样本 x 具有相同标签和不同标签的样本。\n",
    "        使用 while 循环确保 idx1 处的样本与当前样本标签 y 相同，而 idx2 处的样本标签与 y 不同。\n",
    "        最终返回一个包含三个样本和一个标签的元组，即当前样本 x、与 x 标签相同的样本、与 x 标签不同的样本和标签 y。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e909671b-1f22-488b-9af2-07525af1ee45",
   "metadata": {},
   "source": [
    "class my_dataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x_data[idx]\n",
    "        y = self.y_data[idx]\n",
    "        possibility = np.random.rand()\n",
    "        idx1 = np.random.randint(0, len(self.y_data) - 1)\n",
    "        idx2 = np.random.randint(0, len(self.y_data) - 1)\n",
    "        while self.y_data[idx1] != y:\n",
    "            idx1 = np.random.randint(0, len(self.y_data) - 1)\n",
    "        while self.y_data[idx2] == y:\n",
    "            idx2 = np.random.randint(0, len(self.y_data) - 1)\n",
    "        return x, self.x_data[idx1],self.x_data[idx2],y"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d305fe64-2158-4229-bba2-a45030dc6a67",
   "metadata": {},
   "source": [
    "通过函数加载数据集中的数据后，创建自定义数据集的实例并放入DataLoader中用于训练/测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6d1ec8b-9ffe-4935-8bb6-1c5e944636df",
   "metadata": {},
   "source": [
    "train_x_data, train_y_data = get_data(train_data)\n",
    "test_x_data, test_y_data = get_data(test_data)\n",
    "train_dataset = my_dataset(train_x_data, train_y_data)\n",
    "test_dataset = my_dataset(test_x_data, test_y_data)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "77ed13d0-a09f-41f5-8d8b-5b6d49775629",
   "metadata": {},
   "source": [
    "构建孪生神经网络（Siamese类）用于对比学习任务\n",
    "    网络结构\n",
    "        卷积层和激活函数：\n",
    "            第一层：nn.Conv2d(1, 4, kernel_size=3, padding=1, stride=1) 和 nn.ReLU()。\n",
    "            第二层：nn.Conv2d(4, 8, kernel_size=3, padding=1, stride=1) 和 nn.ReLU()。\n",
    "            第三层：nn.Conv2d(8, 16, kernel_size=3, padding=1, stride=1) 和 nn.ReLU()。\n",
    "            第四层：nn.Conv2d(16, 4, kernel_size=3, padding=1, stride=1) 和 nn.ReLU()。\n",
    "        批量归一化层：\n",
    "            在每个卷积层后面，都有相应的批量归一化层：nn.BatchNorm2d(4), nn.BatchNorm2d(8), nn.BatchNorm2d(16), nn.BatchNorm2d(4)。\n",
    "            扁平化层：\n",
    "            nn.Flatten()：将多维的卷积输出展平为一维。\n",
    "        Dropout层：\n",
    "            nn.Dropout(0.2)：防止过拟合。\n",
    "        全连接层：\n",
    "            nn.Linear(3136, out_features=4096)：将展平后的特征映射到一个高维空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d4eb2cd-e1ce-401d-86a0-300f7bf87c32",
   "metadata": {},
   "source": [
    "class Siamese(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.Conv2d(4, 8, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 4, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(3136, out_features=4096),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dcf409ae-68ae-4f54-bec6-6c9d52d2f86f",
   "metadata": {},
   "source": [
    "定义三元组损失函数\n",
    "    输入一个包括锚示例、正示例、负示例的数据三元组，通过优化锚示例与正示例的距离小于锚示例与负示例的距离，实现样本之间的相似性计算。\n",
    "    计算公式如下：\n",
    "        $L = max(d(a,p)-d(a,n)+margin,0)$\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2ac72cd-642f-4ca7-a4df-2e88c044b38a",
   "metadata": {},
   "source": [
    "def triplet_loss(anchor, positive, negative, margin=1.0):\n",
    "    distance_positive = F.pairwise_distance(anchor, positive, p=2)\n",
    "    distance_negative = F.pairwise_distance(anchor, negative, p=2)\n",
    "    losses = F.relu(distance_positive - distance_negative + margin)\n",
    "    return losses.mean()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "102a7e04-76cb-4fb2-ab4c-9857a587cd4d",
   "metadata": {},
   "source": [
    "定义名为AutoEDcoder的类实现了一个卷积神经网络编码器部分，用于从输入图像中提取高维特征表示\n",
    "    编码器结构\n",
    "        卷积层和激活函数：\n",
    "            第一层：nn.Conv2d输入通道为1，输出通道为3，卷积核大小为3，步幅为2，填充为1。\n",
    "            第二层：nn.Conv2d输入通道为3，输出通道为9，卷积核大小为3，步幅为2，填充为1。\n",
    "            第三层：nn.Conv2d输入通道为9，输出通道为18，卷积核大小为3，步幅为2，填充为1。\n",
    "        批量归一化层：\n",
    "            在每个卷积层后面，都有相应的批量归一化层：nn.BatchNorm2d(3), nn.BatchNorm2d(9), nn.BatchNorm2d(18)。\n",
    "        激活函数：\n",
    "            每个批量归一化层后面，跟着一个 LeakyReLU 激活函数：nn.LeakyReLU()。\n",
    "        扁平化层：\n",
    "            nn.Flatten()：将多维的卷积输出展平为一维。\n",
    "        全连接层：\n",
    "            nn.Linear(18 * 4 * 4, 512)：将展平后的特征映射到一个 512 维的空间。\n",
    "            nn.Linear(512, 1024)：进一步将特征映射到一个 1024 维的空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2be2455-a949-4e9f-bf4f-5c617f947759",
   "metadata": {},
   "source": [
    "class AutoEDcoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEDcoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(3, 9, 3, 2, 1),\n",
    "            nn.BatchNorm2d(9),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(9, 18, 3, 2, 1),\n",
    "            nn.BatchNorm2d(18),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(18 * 4 * 4, 512),\n",
    "            nn.Linear(512,1024)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        code = self.encoder(x)\n",
    "        return code"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7a039be5-405d-4de0-8870-73866055223c",
   "metadata": {},
   "source": [
    "定义函数用于训练相关模型\n",
    "    在训练过程中，首先确保模型、数据位于同一个设备，然后通过在每个epoch中遍历整个训练数据集，并通过梯度下降进行优化，以此完成模型的训练。\n",
    "    同时在训练过程中，在每个epoch训练结束时输出并记录该epoch总损失值，用于后续的模型性能评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18310c00-d8a2-4fe7-ad42-e6e41627bb9d",
   "metadata": {},
   "source": [
    "def train(model, train_loader, optimizer, epochs, device):\n",
    "    model = model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i, (x1, x2, x3, y) in enumerate(train_loader):\n",
    "            x1, x2, x3,y = x1.to(device), x2.to(device), x3.to(device),y.to(device)\n",
    "            pred1 = model(x1)\n",
    "            pred2 = model(x2)\n",
    "            pred3 = model(x3)\n",
    "            loss = triplet_loss(pred1, pred2, pred3,margin=10.0)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.detach().cpu().numpy()\n",
    "        loss_list.append(total_loss)\n",
    "        print(f'epoch:{epoch + 1} total_loss:{total_loss}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e22d1a34-d4db-4d03-a699-30364f297ee1",
   "metadata": {},
   "source": [
    "eval函数用于评估相关的模型性能\n",
    "    评估方式如下：\n",
    "        模型设置与训练损失绘制：\n",
    "            设置模型为评估模式，以禁用Dropout层等在训练模式下的功能。\n",
    "            使用matplotlib库绘制训练过程中记录的损失值，展示损失随训练周期（epochs）的变化趋势。\n",
    "        3D t-SNE可视化：\n",
    "            使用t-SNE（t-Distributed Stochastic Neighbor Embedding）算法将高维数据降维到三维。\n",
    "            创建一个3D图像窗口，用于绘制降维后的数据点。\n",
    "            遍历测试数据集，将数据传递给模型并获取预测结果。\n",
    "            对预测结果进行t-SNE降维，并对结果进行标准化处理，以确保数据点在图像中的分布均匀。\n",
    "            在3D图像中绘制降维后的数据点，并为每个数据点标注其标签值。\n",
    "        2D t-SNE可视化：\n",
    "            使用t-SNE算法将高维数据降维到二维。\n",
    "            遍历测试数据集，将数据传递给模型并获取预测结果。\n",
    "            对预测结果进行t-SNE降维，并对结果进行标准化处理。\n",
    "            在2D图像中绘制降维后的数据点，并为每个数据点着色，以反映其标签值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a7a9f66-e66e-47ee-8f0b-df35ac833d3c",
   "metadata": {},
   "source": [
    "def eval(model, device, test_loader, epochs):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    x = [i for i in range(epochs)]\n",
    "    plt.plot(x, loss_list)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    tsne3d = TSNE(n_components=3, init='pca', perplexity=30., random_state=0, learning_rate=300)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    with torch.no_grad():\n",
    "        num=0\n",
    "        for x, _, _, y in test_loader:\n",
    "            x, y = x.to(device), y.detach().cpu().numpy()\n",
    "            y_pred = model(x)\n",
    "            np_y_pred = y_pred.detach().cpu().numpy()\n",
    "            result = tsne3d.fit_transform(np_y_pred)\n",
    "            x_min, x_max = result.min(0), result.max(0)\n",
    "            result = (result - x_min) / (x_max - x_min)\n",
    "            ax.scatter(result[:, 0], result[:, 1], result[:, 2], c=y, cmap='jet')\n",
    "            for i, txt in enumerate(y):\n",
    "                ax.text(result[i, 0], result[i, 1], result[i, 2], str(txt))\n",
    "            num += 1\n",
    "            if num == 3:\n",
    "                break\n",
    "        plt.show()\n",
    "    tsne2d = TSNE(n_components=2, init='pca', perplexity=30., random_state=0, learning_rate=300)\n",
    "    with (torch.no_grad()):\n",
    "        num = 0\n",
    "        for x, _, _, y in test_loader:\n",
    "            x, y = x.to(device), y.detach().cpu().numpy()\n",
    "            y_pred = model(x)\n",
    "            np_y_pred = y_pred.detach().cpu().numpy()\n",
    "            result = tsne2d.fit_transform(np_y_pred)\n",
    "            x_min, x_max = result.min(0), result.max(0)\n",
    "            result = (result - x_min) / (x_max - x_min)\n",
    "            plt.scatter(result[:, 0], result[:, 1], c=y, cmap='jet')\n",
    "            num+=1\n",
    "            if num==3:\n",
    "                break\n",
    "        plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f1f25b59-a488-4036-8520-ea3569195464",
   "metadata": {},
   "source": [
    "对孪生网络模型进行训练，并将对应的训练结果保存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76c51c80-6ac9-42ae-a9e1-1c164854be53",
   "metadata": {},
   "source": [
    "print('===========Siamese===========')\n",
    "model = Siamese(output_size=10)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train(model, train_loader, optimizer, epochs, device)\n",
    "# torch.save(model, '实现了一个卷积神经网络编码器部分，用于从输入图像中提取高维特征表示')\n",
    "eval(model, device, test_loader, epochs)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c45a45b3-cb23-4328-858a-a2cfb4661b71",
   "metadata": {},
   "source": [
    "在置空损失函数列表后，对自动编码器的编码器部分进行训练。训练中使用到的超参数同孪生网络训练中超参数一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4670a7c4-c4de-4b82-8044-887aa21dab9b",
   "metadata": {},
   "source": [
    "loss_list = []\n",
    "net = AutoEDcoder()\n",
    "print('===========AutoEDcoder===========')\n",
    "trainer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "train(net, train_loader, trainer, epochs, device)\n",
    "eval(net, device, test_loader, epochs)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
